{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors and Neural Nets, a gentle introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't know very much about tensors ... so I've started to ask for more, finding inspiration from some answers on Quora like the ones [written by\n",
    "William Oliver and Brian Bi](https://www.quora.com/What-is-a-tensor).\n",
    "\n",
    "* Tensors **are not** generalizations or formalizations of vectors or matrices.\n",
    "\n",
    "* Some tensors can be represented as 2D arrays, but these 2D arrays do not necessarily work anything like matrices or not any 2D array is a tensor. The numerical values in a matrix’s representation represent entirely different things than the numerical values in a tensor’s definition.\n",
    "\n",
    "The fundamental definition of the dot product of two vectors x and y **is not** x1y1+x2y2, **it is ||x||||y||cos(θ)**. The former is just a convenient computational shortcut when working in Cartesian coordinates and the latter one is a geometrical operation of the **dot product and the dot product itself is an example of a tensor**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So one definition of a tensor: A tensor is any multilinear map from a vector space to a scalar field ( from my understanding, a tensor maps pairs of vectors into scalars)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with a vector in the XOY plane (**a particular case**), trying to find the x and y components of that vector. (I've followed [this great explanation](https://youtu.be/f5liqUk0ZTw)). But for this, we need the projections of this vector onto of each of the axes (its shadows on x an y axes, or how far we need to go from the origin to the \"tip\" of our vector using the road given by x and y axes).  \n",
    "\n",
    "In this way, we will end up representing our vector as some x and y basis unit vectors (x * i and y * j), using the components as our final vector representation (while knowing the basis components),or representing the vector as an array [ x, y ] (**but** keep in mind that these 2 components pertain only to the vector that we took initially into account for which we've found the components).  \n",
    "\n",
    "**For the general case**, taking the vector A, we will have the Ax, Ay and Az components pertaining to each of the basis components (assuming this time XYZ system of axes or three dimesnional space). We will need only one index because we have only one directional indicator (on basis of vector component) and this is what makes vectors tensors of rank 1. Similarly the scalars are considered tensors of rank 0 because they don't have any directional indicators.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What about higher ranked tensors?**\n",
    "\n",
    "A rank 2 tensor in 3D space representation will have 9 components (having two indices because of the two directional indicators) and 9 sets (combinations) of 2 basis vectors ( such as: xx, xy, xz, yx, yy, yz, zx, zy, zz).\n",
    "\n",
    "\n",
    "A rank 3 tensor in 3D space will be represented by 27 components (9 * 3 slices of tensors)  (having three indices because of the three directional indicators) each pertaining to 27 sets (combinations) of 3 basis vectors (xx**x**, xy**x**, xz**x**, yx**x**, yy**x**, yz**x**, zy**x**, zz**x**, zz**x** etc for the next components (\"slices of tensors\" as I use to visualize them and, one will stwich the third index with y or z for dinding out the rest of the other 18).  \n",
    "\n",
    "Also  Brian Bi mentioned, **the tensor is the geometric object obtained by using the values in the multidimensional array as coefficients to form a linear combination of the unit basis tensors**, and this implies that when you change your coordinate system (let's say x′,y′,z′), the tensor’s components in the new system are obtained in the manner described above, by expressing the old unit basis vectors in terms of the new ones. This then will allows us to expand the tensor in terms of x′,y′,z′, giving the coordinates in the new coordinate system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensors seen through Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3]) torch.Size([2, 5]) torch.Size([3, 2, 3]) torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "# Few examples on tensors to understand their structure \n",
    "\n",
    "# A 1D tensor that looks like a one-line matrix/a vector\n",
    "x = torch.randn((1, 3)) \n",
    "\n",
    "# A 2D tensor that looks like a matrix\n",
    "y = torch.randn((2, 5)) \n",
    "\n",
    "# It will give us a series of 3 tensors containing other tensors of size (2x3)\n",
    "# everything being comprised in the end as a 3D tensor\n",
    "z = torch.randn((3, 2, 3)) \n",
    "\n",
    "# A scalar remains a 0-rank tensor (a tensor without shape) and it can be easily used within operations with other tensors\n",
    "t = torch.randn(0)\n",
    "\n",
    "print(x.size(), y.size(), z.size(), t.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Breaking down the rule that element-wise operations operate on tensors of the same shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the **same shape** is not **fully** the same as being compatible(as I see it).  \n",
    "\n",
    "When operating on two tensors/arrays, Pytorch compares their shapes element-wise. It starts with the trailing dimension (from right to the left), and works its way forward and checks for compatibility, if the dimensions:\n",
    "\n",
    "- are equal  \n",
    "**OR**\n",
    "- one of them is 1\n",
    "\n",
    "If these conditions are not met, an exception is thrown, indicating that the tensors/arrays have **incompatible** shapes.  \n",
    "\n",
    "*However, when the shapes do not match, the shape of the returned output tensor checks for the **broadcasting conditions**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, when doing some operation between a scalar (or one dimension tensor) and another tensor (with more dimensions), the scalar is \"streched\" (or \"copied\", imaginary speaking) without making any other copy/ array that fits the size of the \"bigger\" tensor involved in the operation (so extra memory is not actually allocated).\n",
    "This is the higher level view of broadcasting.\n",
    "\n",
    "**How come !??**\n",
    "\n",
    "Subject to <strong> certain constraints </strong> (the need for having the same shape for one-on-one basis operations), the smaller array (the scalar in our case) is \"broadcast\" across the larger array (the matrix) so that they have compatible shapes (see [numpy documentation](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A . When broadcasting happens\n",
    "\n",
    "Well... not all tensors are broacastable, they are subject to some criteria and broadcasting happens when:  \n",
    "\n",
    "1. each tensor has at least one dimension (<em> so practically a tensor should be at least 1D tensor, looking like a vector </em>);  \n",
    "\n",
    "2. iterating over the dimension sizes, starting at the trailing dimension (<em> one can do the checking backwards to see each dimension and compare </em>), the dimension sizes must either be equal, one of them is 1, or one of them does not exist.  \n",
    "\n",
    "See more details [in Pytorch's documentation](https://pytorch.org/docs/stable/notes/broadcasting.html) and also [in this interesting blogpost](https://mc.ai/broadcasting-with-pytorch/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. For the beginning,  let's imagine broadcasting with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will play a bit with Numpy... because normally I would not do a sum between 1D and 2D arrays and I wanted to see how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only requirement for broadcasting is a way of aligning array dimensions such that either (check [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) the documentation):\n",
    "\n",
    "* **aligned dimensions** are equal;\n",
    "* one of the aligned dimensions is 1.\n",
    "\n",
    "And btw...arrays **do not need** to have **the same number of dimensions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 7 8]\n",
      "[[1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]]\n",
      "[[0 1 2 3 4]\n",
      " [1 2 3 4 5]\n",
      " [2 3 4 5 6]\n",
      " [3 4 5 6 7]]\n",
      "[[ 1  2  3]\n",
      " [11 12 13]\n",
      " [21 22 23]\n",
      " [31 32 33]]\n"
     ]
    }
   ],
   "source": [
    "# add vector and scalar--> vector\n",
    "a = np.arange(4) + 5\n",
    "print(a)\n",
    "\n",
    "# add a matrix(2 axes/2D array) and a vector (one axis/1D array)--> 2D array\n",
    "b = np.ones((4,3)) + np.arange(3)\n",
    "c = np.arange(4).reshape((4,1)) + np.arange(5)\n",
    "\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "# add 2 vectors (vec column + vec row results in a matrix, damn it !!\n",
    "aa = np.array([0, 10, 20, 30]) #aa(1,4)\n",
    "bb = np.array([1, 2, 3])\n",
    "# add an extra axis to the array, resulting in column vector aa(4,1) + row vector--> 2D array\n",
    "print (aa[:, np.newaxis] + bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Broadcasting with tensors, after checking the broadcasting conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When iterating through each tensor's dimension we find that dimensions are not equal, we reconsider the smaller dimension to the level of the bigger dimension of the other tensor (it's like taking the max between the two dimensions compared)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D + 1D tensors--> 2D tensor\n",
    "a = torch.tensor([[1, 2, 1],\n",
    "                  [2, 3, 1]],\n",
    "                 )    \n",
    "b = torch.ones(3)\n",
    "print(a.size())\n",
    "print(b.size())\n",
    "\n",
    "(a+b).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# They are broadcastble: 4D + 3D in this case\n",
    "a_tensor = torch.randn(1,2,4,1)\n",
    "b_tensor = torch.randn(2,1,1)\n",
    "\n",
    "print((a_tensor + b_tensor).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-8f9109f44d83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb_tensor_not\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0ma_tensor_not\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_tensor_not\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# They are not broadcastble ( because 3!=2 in the third trailing dimension)\n",
    "a_tensor_not = torch.randn(1,3,4,1)\n",
    "b_tensor_not = torch.randn(2,1,1)\n",
    "\n",
    "(a_tensor_not + b_tensor_not).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Broadcasting is possible with matmul but not with mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matmul's behaviour depends on the dimensionality of the tensors (if broadcasting rules apply), while the mm function follows the mathematical rules for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 4, 1])\n",
      "torch.Size([1, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting situations in matmul function\n",
    "test5 = torch.randn(1, 2, 4, 1)\n",
    "test6 = torch.randn(2, 1, 1)\n",
    "# print(test5)\n",
    "# print(test6)\n",
    "output1 = torch.matmul(test5, test6)\n",
    "print(output1.shape)\n",
    "\n",
    "test7 = torch.randn(1, 2, 3)\n",
    "test8 = torch.randn( 3, 2)\n",
    "output2 = torch.matmul(test7, test8)\n",
    "print(output2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how I see in slow motion a broadcasting case:\n",
    "\n",
    "1. [x] Both tensors are at least 1D;\n",
    "2. [x] I check backwards (on each dimension level) the dimension of each tensor;  \n",
    "In the above example, sizes of (4x1) and (1x1) allow for the multiplication resulting in 4x1 size tensors (it makes sense/more logic to me to compare the dimensions like this when it comes to multiplication);\n",
    "3. [x] Then I iterate on the next dimension (with the value 1 and 1, so sizes are equal between the tensors);\n",
    "4. [x] Then for the 4th trailing dimension, one of the tensors doesn't have the 3rd dimension and it will \"borrow\" the third dimension from the other one. \n",
    "\n",
    "\n",
    "\n",
    "![Check for broadcasting case](Images/Capture_broadcasting_matmul.JPG \"Another example of checking broadcasting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matmul function does broadcasting\n",
    "a1_tensor = torch.randn(2, 3)\n",
    "b1_tensor = torch.randn(3)\n",
    "torch.matmul(a1_tensor, b1_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 4D, 3D tensors at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensorMath.cpp:131",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-40853baa9af9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: matrices expected, got 4D, 3D tensors at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensorMath.cpp:131"
     ]
    }
   ],
   "source": [
    "# MM function does not support for broadcasting\n",
    "a = torch.randn(2, 3)\n",
    "b = torch.randn(2)\n",
    "output2 = torch.mm(a,b)\n",
    "output2.shape\n",
    "\n",
    "a1 = torch.randn(1, 2, 4, 1)\n",
    "b1 = torch.randn(2, 1, 1)\n",
    "torch.mm(a1, b1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2  Visualizing the sum of the elements within a tensor's dimension\n",
    " \n",
    "One can have even more details after reading [this good article](https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be).\n",
    "\n",
    "Depending on the dimension chosen for the operation (**assuming here the case of a 3D tensor**) we analyzed:\n",
    "-  the sum on the 0 dimension  (we could imagine this as a sum along all \"slices\" of tensors, colapsing the slices of tensors)    \n",
    "-  the sum on the 1 dimension (we could think of a sum along the rows of each tensor, colapsing the rows of each tensor)    \n",
    "\n",
    "-  the sum on the 2 dimension  (we could associate it with a sum along the olumns of each tensor, colapsing the rows of each tensor)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3,  6,  9],\n",
      "        [11, 13, 15]])\n",
      "tensor([[5, 7, 9],\n",
      "        [4, 5, 6],\n",
      "        [5, 7, 9]])\n",
      "tensor([[ 6, 15],\n",
      "        [ 6,  9],\n",
      "        [ 6, 15]])\n"
     ]
    }
   ],
   "source": [
    "#test4 is a 3D tensor(containing other 3 tensors each one having 2x3 size.shape)\n",
    "test4 = torch.tensor([\n",
    "     [\n",
    "       [1, 2, 3],\n",
    "       [4, 5, 6]\n",
    "     ],\n",
    "     [\n",
    "       [1, 2, 3],\n",
    "       [3, 3, 3]\n",
    "     ],\n",
    "     [\n",
    "       [1, 2, 3],\n",
    "       [4, 5, 6]\n",
    "     ]\n",
    "   ])\n",
    "\n",
    "# when summing on 0 dimension\n",
    "calapse_tensors = torch.sum(test4, dim=0) \n",
    "print(calapse_tensors)\n",
    "\n",
    "# when summing on 1 dimension\n",
    "calapse_rows = torch.sum(test4, dim=1) \n",
    "print(calapse_rows)\n",
    "\n",
    "# when summing on 2 dimension\n",
    "colapse_columns = torch.sum(test4, dim=2)\n",
    "print(colapse_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coming back to the calculation output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 For one layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\" Sigmoid activation function \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Note</strong> \n",
    "I will choose between more ways of having the vector column  ([`source`](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics)):\n",
    "1. input_tensor.reshape (find put more about it), \n",
    "2. input_tensor.resize_ which is an  in place operation that changes directly the content of a tensor\n",
    "3. or input_tensor.view, which will give a new tensor with the same input tensor data. \n",
    "\n",
    "Here is a great forum thread to [read more about in-place operations](https://discuss.pytorch.org/t/what-is-in-place-operation/16244) in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few options here: [`weights.reshape()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.reshape), [`weights.resize()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.resize_), and [`weights.view()`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch._C.Generator object at 0x000001DBCD51A250>\n",
      "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
      "torch.Size([1, 5])\n",
      "tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n",
      "tensor([[-0.8948],\n",
      "        [-0.3556],\n",
      "        [ 1.2324],\n",
      "        [ 0.1382],\n",
      "        [-1.6822]])\n",
      "tensor([[0.3177]])\n"
     ]
    }
   ],
   "source": [
    "### Generate some data\n",
    "data = torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "print(data)\n",
    "\n",
    "# Features are 5 random normal variables\n",
    "features = torch.randn((1, 5)) # a tensor matrix 1x5 dimension, randomly generated according to the N(0,1)\n",
    "print(features)\n",
    "print(features.size())\n",
    "\n",
    "# True weights for our data, random normal variables again\n",
    "weights = torch.randn_like(features)\n",
    "print(weights)\n",
    "\n",
    "# change the shape of one line matrix tensor of weights to one column dimension with the help of tensor_input.view ( desired dimension)\n",
    "print(weights.view(5,1))\n",
    "\n",
    "# and a true bias term(a tensor as wel)\n",
    "bias = torch.randn((1, 1))\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the output of this network using the weights and bias tensors (it works in this way because we are dealing with vectors !!!!)\n",
    "y1 = activation(torch.sum(features * weights) + bias)\n",
    "# OR\n",
    "y2 = activation((features * weights).sum() + bias)\n",
    "# Calculate the output of a node in the network using matrix multiplication\n",
    "# activation(sum(torch.matmul(features, column_weights), bias))\n",
    "y3 = activation(torch.mm(features, weights.view(5,1))+ bias)\n",
    "# OR \n",
    "y33 = activation(torch.matmul(features, weights.view(5,1)) + bias)\n",
    "y333 = activation(sum(torch.matmul(features, weights.view(5,1)), bias))\n",
    "\n",
    "# print(y3, y33, y333, y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1282, -0.0747, -0.9838, -0.2720],\n",
      "         [ 0.8230, -0.8795,  1.9651,  1.7311],\n",
      "         [ 0.2184, -0.5579, -0.6674, -0.2830]],\n",
      "\n",
      "        [[-2.1402,  0.8374,  0.2073,  0.8716],\n",
      "         [-0.9958,  1.7378, -1.0768, -1.2173],\n",
      "         [-0.2837,  1.1372,  0.8003,  0.2198]]]) tensor([[-0.5145],\n",
      "        [ 1.5680],\n",
      "        [ 0.1112],\n",
      "        [-0.0949]])\n",
      "tensor([[[-0.1348],\n",
      "         [-1.7482],\n",
      "         [-1.0345]],\n",
      "\n",
      "        [[ 2.3546],\n",
      "         [ 3.2329],\n",
      "         [ 1.9973]]])\n"
     ]
    }
   ],
   "source": [
    "## !!! Calculate the output of a node in the network using matrix multiplication with matmul ,  \n",
    "# BUT matmul broatcasts (it allows operations between diferrent sizes of tensor under some conditions, see Note 1 above)\n",
    "tensor1 = torch.randn(2, 3, 4)\n",
    "tensor2 = torch.randn(4,1)\n",
    "print(tensor1, tensor2)\n",
    "torch.matmul(tensor1, tensor2).size()\n",
    "print(torch.matmul(tensor1, tensor2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 When having one hidden layer with 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "3\n",
      "torch.Size([3, 2])\n",
      "tensor([[-1.6822],\n",
      "        [ 0.3177]])\n",
      "tensor([[0.1328, 0.1373]])\n"
     ]
    }
   ],
   "source": [
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 3 random normal variables\n",
    "features = torch.randn([1, 3]) # we have a 2D tensor\n",
    "print(features.shape)\n",
    "\n",
    "# Define the size of each layer in our network\n",
    "n_input = features.shape[1]     # Number of input units, must match number of input features\n",
    "print(n_input)\n",
    "\n",
    "n_hidden = 2                    # Number of hidden units, we will have 2 nodes in the hidden layer\n",
    "n_output = 1                    # Number of output units\n",
    "\n",
    "# Weights for inputs to hidden layer\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "print(W1.shape)\n",
    "# Weights for hidden layer to output layer\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "print(W2)\n",
    "\n",
    "# and bias terms for hidden and output layers\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "print(B1)\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "1. h will be the hidden layer with 2 nodes;\n",
    "\n",
    "2. h is a tensor resulted from the activation function applied to (features * W1 + B1);\n",
    "\n",
    "3. output is a tensor resulted from teh activation function applied to (h * W2 + B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6813, 0.4355]])\n",
      "tensor([[0.3171]])\n"
     ]
    }
   ],
   "source": [
    "h = activation(torch.mm(features, W1) + B1)\n",
    "print(h)\n",
    "Y= activation(torch.mm(h, W2) + B2)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: tensor.shape[ ] and tensor.size() mean one and the same thing.  \n",
    "\n",
    "They count for the number of elements along a dimension (depending of course if these functions take an argument or not). If they take an argument they refer to the shape/size of that dimension taken as argument (the mmax value for argument is no of dimensions-1, the minimum value is 0 meaning first dimension). If they don't have an argument, the function return the shape/size of the tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5) torch.Size([])\n",
      "tensor([5, 6]) torch.Size([2])\n",
      "2\n",
      "tensor([[5, 6]]) torch.Size([1, 2])\n",
      "1\n",
      "tensor([1, 3]) torch.Size([2])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor(5)\n",
    "print(t1, t1.shape) # the 0D tensor\n",
    "\n",
    "t11= torch.tensor([5,6]) # a 1D tensor\n",
    "print(t11, t11.shape)\n",
    "print(t11.shape[0])\n",
    "\n",
    "t12= torch.tensor([[5,6]]) #a 2D tensor, it is taken as tensor[1,2]\n",
    "print(t12, t12.shape)\n",
    "print(t12.shape[0])\n",
    "\n",
    "t13= torch.tensor((1,3)) # a 1D tensor\n",
    "print(t13, t11.shape)\n",
    "print(t13.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 4, 6, 7],\n",
      "        [1, 5, 7, 9]]) torch.Size([2, 4])\n",
      "2\n",
      "4\n",
      "4\n",
      "tensor([[10,  2],\n",
      "        [ 5,  3],\n",
      "        [11,  5]]) torch.Size([3, 2])\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[5, 4, 6, 7],[1, 5, 7, 9]])\n",
    "print(t2, t2.shape)\n",
    "print(t2.shape[0])\n",
    "\n",
    "print(t2.shape[1])\n",
    "# OR\n",
    "print(t2.size(1))\n",
    "\n",
    "t3 = torch.tensor([[10,2], [5,3], [11,5]])\n",
    "print(t3, t3.shape) \n",
    "print(t3.shape[0]) \n",
    "print(t3.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10],\n",
      "         [ 5]],\n",
      "\n",
      "        [[ 4],\n",
      "         [ 5]],\n",
      "\n",
      "        [[ 5],\n",
      "         [ 7]]]) torch.Size([3, 2, 1])\n",
      "3\n",
      "2\n",
      "1\n",
      "tensor([[[[10],\n",
      "          [ 5]],\n",
      "\n",
      "         [[ 4],\n",
      "          [ 5]],\n",
      "\n",
      "         [[ 5],\n",
      "          [ 7]]]]) torch.Size([1, 3, 2, 1])\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.tensor([[[10],[5]],[[4], [5]], [[5],[7]]]) # a 3D tensor\n",
    "print(t4, t4.shape) #  is torch.Size([3, 2, 1])\n",
    "print(t4.shape[0])\n",
    "print(t4.shape[1])\n",
    "print(t4.shape[2])\n",
    "\n",
    "t = torch.unsqueeze(t4, 0) # is a 4D tensor, the second argument in unsqueeze adds an extra dimension\n",
    "# t will be  torch.Size([1, 3, 2, 1]) \n",
    "print(t, t.shape) \n",
    "print(t.shape[0])\n",
    "print(t.shape[1])\n",
    "print(t.shape[2])\n",
    "print(t.shape[3])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Switching between Numpy's arrays and Pytorch's tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78868662, 0.73321195, 0.47463454],\n",
       "       [0.3379168 , 0.85028137, 0.99561204],\n",
       "       [0.54409091, 0.66113114, 0.93360019],\n",
       "       [0.25007664, 0.11012498, 0.82379173]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7887, 0.7332, 0.4746],\n",
       "        [0.3379, 0.8503, 0.9956],\n",
       "        [0.5441, 0.6611, 0.9336],\n",
       "        [0.2501, 0.1101, 0.8238]], dtype=torch.float64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a) \n",
    "b # is the array a transformed into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.57737324, 1.46642389, 0.94926907],\n",
       "       [0.67583361, 1.70056273, 1.99122408],\n",
       "       [1.08818182, 1.32226228, 1.86720038],\n",
       "       [0.50015328, 0.22024995, 1.64758346]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy() # wuth .numpy() we bring back the tensor b into a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1547, 2.9328, 1.8985],\n",
       "        [1.3517, 3.4011, 3.9824],\n",
       "        [2.1764, 2.6445, 3.7344],\n",
       "        [1.0003, 0.4405, 3.2952]], dtype=torch.float64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mul_(2) # an in place operation that changes the orginal tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.15474647, 2.93284778, 1.89853815],\n",
       "       [1.35166722, 3.40112547, 3.98244815],\n",
       "       [2.17636364, 2.64452456, 3.73440075],\n",
       "       [1.00030656, 0.4404999 , 3.29516692]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a  # a has changed as well after the change of \"its\" tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
